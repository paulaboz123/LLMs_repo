{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Azure ML v2 SDK \u2014 redeploy LLM (Azure OpenAI) under existing Managed Online Endpoint\n",
        "\n",
        "Cel: podmieni\u0107 **jeden deployment** pod istniej\u0105cym endpointem, zrobi\u0107 mu **100% traffic** (konfigurowalne, bez hardcode), a po drodze mie\u0107 **deterministyczne testy diagnostyczne**: czy dzia\u0142a \u015brodowisko, czy SDK, czy uprawnienia, czy build obrazu, czy `score.py`, czy ruch/keys.\n",
        "\n",
        "Ten notebook zak\u0142ada:\n",
        "- Endpoint ju\u017c istnieje.\n",
        "- Pod endpointem s\u0105 2+ deploymenty.\n",
        "- Chcesz stworzy\u0107/od\u015bwie\u017cy\u0107 jeden deployment (np. `llm`), przetestowa\u0107 go, a nast\u0119pnie (opcjonalnie) przestawi\u0107 traffic.\n",
        "\n",
        "\u0179r\u00f3d\u0142a referencyjne: dokumentacja Azure ML online endpoints i traffic allocation. \ue200cite\ue202turn0search1\ue202turn0search3\ue202turn0search5\ue201\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 0) (Opcjonalnie) aktualizacja paczek w notebook compute\n",
        "# Uwaga: je\u015bli dzia\u0142asz na Compute Instance w AML, %pip jest OK. Lokalnie u\u017cyj pip/conda.\n",
        "%pip install -U azure-ai-ml azure-identity azure-core pyyaml pandas openpyxl python-dotenv openai requests\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Konfiguracja \u2014 w jednym miejscu\n",
        "\n",
        "Wa\u017cne:\n",
        "- **Nie** hardcodujemy trafficu w kodzie \u201ena zawsze\u201d. U\u017cywamy zmiennych steruj\u0105cych i funkcji `set_traffic(...)`.\n",
        "- `NEW_DEPLOYMENT_NAME` to deployment, kt\u00f3ry podmieniasz/od\u015bwie\u017casz.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# === AML Workspace ===\n",
        "SUBSCRIPTION_ID = os.getenv(\"AZURE_SUBSCRIPTION_ID\", \"REPLACE_ME\")\n",
        "RESOURCE_GROUP  = os.getenv(\"AZURE_RESOURCE_GROUP\",  \"REPLACE_ME\")\n",
        "WORKSPACE_NAME  = os.getenv(\"AZUREML_WORKSPACE\",     \"REPLACE_ME\")\n",
        "\n",
        "# === Existing Online Endpoint ===\n",
        "ENDPOINT_NAME = os.getenv(\"AML_ENDPOINT_NAME\", \"REPLACE_ME\")  # istniej\u0105cy endpoint\n",
        "\n",
        "# === Deployment to (re)create ===\n",
        "NEW_DEPLOYMENT_NAME = os.getenv(\"AML_NEW_DEPLOYMENT_NAME\", \"llm\")  # ten podmieniasz\n",
        "\n",
        "# Compute for deployment\n",
        "INSTANCE_TYPE  = os.getenv(\"AML_INSTANCE_TYPE\", \"Standard_DS3_v2\")\n",
        "INSTANCE_COUNT = int(os.getenv(\"AML_INSTANCE_COUNT\", \"1\"))\n",
        "\n",
        "# Folder z kodem scoringu\n",
        "CODE_DIR = Path(\"./src_llm\")\n",
        "CODE_DIR.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Environment asset (z conda yaml)\n",
        "CONDA_YAML_PATH = Path(\"./conda_env.yml\")  # w tym \u015brodowisku notebooka masz ju\u017c plik z uploadu; tu trzymamy kopi\u0119\n",
        "ENV_NAME = os.getenv(\"AML_ENV_NAME\", \"openai-rag-demand-labeler\")\n",
        "ENV_VERSION = os.getenv(\"AML_ENV_VERSION\", \"1\")  # mo\u017cesz bumpowa\u0107 gdy zmieniasz zale\u017cno\u015bci\n",
        "\n",
        "# === Traffic control ===\n",
        "SET_TRAFFIC_AFTER_SMOKE_TEST = os.getenv(\"AML_SET_TRAFFIC\", \"true\").lower() == \"true\"\n",
        "NEW_DEPLOYMENT_TRAFFIC_PERCENT = int(os.getenv(\"AML_NEW_DEPLOYMENT_TRAFFIC_PERCENT\", \"100\"))\n",
        "\n",
        "assert 0 <= NEW_DEPLOYMENT_TRAFFIC_PERCENT <= 100, \"Traffic percent must be 0..100\"\n",
        "print(\"Config OK\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Diagnostyka \u015brodowiska notebooka (lokalnego/Compute Instance)\n",
        "\n",
        "To ma odpowiedzie\u0107 na pytania:\n",
        "- czy paczki s\u0105 zainstalowane?\n",
        "- czy wersje s\u0105 sensowne?\n",
        "- czy widzisz `conda_env.yml`?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys, platform, importlib, pkgutil\n",
        "import azure.ai.ml\n",
        "import azure.identity\n",
        "import openai\n",
        "\n",
        "print(\"Python:\", sys.version)\n",
        "print(\"Platform:\", platform.platform())\n",
        "print(\"azure-ai-ml:\", azure.ai.ml.__version__)\n",
        "print(\"azure-identity:\", azure.identity.__version__)\n",
        "print(\"openai:\", openai.__version__)\n",
        "print(\"CONDA_YAML_PATH exists?:\", CONDA_YAML_PATH.exists(), str(CONDA_YAML_PATH.resolve()))\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Wgraj/od\u015bwie\u017c `conda_env.yml` w katalogu roboczym notebooka\n",
        "\n",
        "Masz za\u0142\u0105czony plik `/mnt/data/conda_env.yml`. Skopiujemy go do bie\u017c\u0105cego katalogu, aby Environment asset m\u00f3g\u0142 si\u0119 z niego budowa\u0107.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import shutil\n",
        "\n",
        "SRC_UPLOADED_CONDA = Path(\"/mnt/data/conda_env.yml\")\n",
        "if SRC_UPLOADED_CONDA.exists():\n",
        "    shutil.copy2(SRC_UPLOADED_CONDA, CONDA_YAML_PATH)\n",
        "    print(\"Copied conda yaml from:\", SRC_UPLOADED_CONDA)\n",
        "else:\n",
        "    raise FileNotFoundError(f\"Nie widz\u0119 {SRC_UPLOADED_CONDA}. Dodaj plik albo zmie\u0144 \u015bcie\u017ck\u0119.\")\n",
        "\n",
        "print(CONDA_YAML_PATH.read_text(encoding=\"utf-8\")[:1000])\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Wygeneruj kod inferencji (`score.py`) i przyk\u0142adowe dane `demands.xlsx`\n",
        "\n",
        "Ten krok jest **samowystarczalny**: w folderze `CODE_DIR` powstanie `score.py` i `demands.xlsx`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "# --- demands.xlsx (przyk\u0142ad; mo\u017cesz podmieni\u0107 na swoje) ---\n",
        "demands_path = CODE_DIR / \"demands.xlsx\"\n",
        "if not demands_path.exists():\n",
        "    df = pd.DataFrame([\n",
        "        {\"demand_id\":\"motor-earthing\",\"demand\":\"motor - earthing\",\"description\":\"Wym\u00f3g pod\u0142\u0105czenia silnika/ramy do PE / uziemienia.\"},\n",
        "        {\"demand_id\":\"motor-ip\",\"demand\":\"motor - IP\",\"description\":\"Wym\u00f3g klasy szczelno\u015bci (np. IP55, IP66).\"},\n",
        "        {\"demand_id\":\"motor-iso9001\",\"demand\":\"motor - ISO9001\",\"description\":\"Wym\u00f3g certyfikacji ISO 9001 (dokument/certyfikat).\"},\n",
        "    ])\n",
        "    df.to_excel(demands_path, index=False)\n",
        "    print(\"Created:\", demands_path)\n",
        "else:\n",
        "    print(\"Exists:\", demands_path)\n",
        "\n",
        "# --- score.py ---\n",
        "score_path = CODE_DIR / \"score.py\"\n",
        "score_path.write_text('import os\\nimport json\\nimport logging\\nimport time\\nfrom typing import Any, Dict, List, Optional\\n\\nimport numpy as np\\nimport pandas as pd\\nfrom openai import AzureOpenAI\\n\\nlogging.basicConfig(level=logging.INFO)\\nlogger = logging.getLogger(__name__)\\n\\nclient: Optional[AzureOpenAI] = None\\nDEMANDS: List[Dict[str, str]] = []\\nDEMAND_EMB: Optional[np.ndarray] = None\\n\\nAZURE_CHAT_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT\", \"\").strip()\\nAZURE_EMBED_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_EMBED_DEPLOYMENT\", \"\").strip()\\n\\nTOP_K_RAG = int(os.getenv(\"TOP_K_RAG\", \"8\"))\\nMAX_LABELS_PER_CHUNK = int(os.getenv(\"MAX_LABELS_PER_CHUNK\", \"3\"))\\nMIN_KEEP_PROBA = float(os.getenv(\"MIN_KEEP_PROBA\", \"0.30\"))\\nMAX_TEXT_CHARS = int(os.getenv(\"MAX_TEXT_CHARS\", \"4000\"))\\n\\ndef _l2_normalize(x: np.ndarray) -> np.ndarray:\\n    denom = (np.linalg.norm(x, axis=1, keepdims=True) + 1e-12)\\n    return x / denom\\n\\ndef _safe_float(v: Any, default: float = 0.0) -> float:\\n    try:\\n        return float(v)\\n    except Exception:\\n        return default\\n\\ndef _safe_json_loads(s: str) -> Optional[dict]:\\n    try:\\n        return json.loads(s)\\n    except Exception:\\n        return None\\n\\ndef init():\\n    global client, DEMANDS, DEMAND_EMB, AZURE_CHAT_DEPLOYMENT, AZURE_EMBED_DEPLOYMENT\\n    logger.info(\"INIT: starting...\")\\n\\n    endpoint = (os.getenv(\"AZURE_OPENAI_ENDPOINT\") or \"\").strip()\\n    api_key = (os.getenv(\"AZURE_OPENAI_API_KEY\") or \"\").strip()\\n    api_version = (os.getenv(\"AZURE_OPENAI_API_VERSION\") or \"2024-12-01-preview\").strip()\\n\\n    AZURE_CHAT_DEPLOYMENT = (os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT\") or \"\").strip()\\n    AZURE_EMBED_DEPLOYMENT = (os.getenv(\"AZURE_OPENAI_EMBED_DEPLOYMENT\") or \"\").strip()\\n\\n    if not endpoint or not api_key:\\n        logger.error(\"Missing AZURE_OPENAI_ENDPOINT or AZURE_OPENAI_API_KEY.\")\\n        return\\n    if not AZURE_CHAT_DEPLOYMENT or not AZURE_EMBED_DEPLOYMENT:\\n        logger.error(\"Missing AZURE_OPENAI_CHAT_DEPLOYMENT or AZURE_OPENAI_EMBED_DEPLOYMENT.\")\\n        return\\n\\n    client = AzureOpenAI(azure_endpoint=endpoint, api_key=api_key, api_version=api_version)\\n\\n    base_dir = os.path.dirname(os.path.abspath(__file__))\\n    demands_path = os.path.join(base_dir, \"demands.xlsx\")\\n    if not os.path.exists(demands_path):\\n        logger.error(f\"demands.xlsx not found at: {demands_path}\")\\n        return\\n\\n    df = pd.read_excel(demands_path)\\n    required_cols = {\"demand_id\", \"demand\", \"description\"}\\n    if not required_cols.issubset(df.columns):\\n        logger.error(f\"demands.xlsx missing columns. Required: {required_cols}, got: {set(df.columns)}\")\\n        return\\n\\n    DEMANDS = []\\n    embed_inputs: List[str] = []\\n    for _, row in df.iterrows():\\n        did = str(row[\"demand_id\"]).strip()\\n        name = str(row[\"demand\"]).strip()\\n        desc = str(row[\"description\"]).strip()\\n        if not did or did.lower() == \"nan\":\\n            continue\\n        if not name or name.lower() == \"nan\":\\n            continue\\n        DEMANDS.append({\"id\": did, \"name\": name, \"description\": desc})\\n        embed_inputs.append(f\"Name: {name}\\\\nClarification: {desc}\")\\n\\n    if not DEMANDS:\\n        logger.error(\"No demands loaded from Excel (DEMANDS is empty).\")\\n        return\\n\\n    t0 = time.time()\\n    emb = client.embeddings.create(model=AZURE_EMBED_DEPLOYMENT, input=embed_inputs)\\n    DEMAND_EMB = _l2_normalize(np.array([e.embedding for e in emb.data], dtype=np.float32))\\n    logger.info(f\"INIT: loaded {len(DEMANDS)} demands. Embedding time: {time.time() - t0:.2f}s\")\\n\\ndef _retrieve_candidates(chunk_text: str, k: int) -> List[Dict[str, str]]:\\n    if client is None or DEMAND_EMB is None or not DEMANDS:\\n        return []\\n    emb = client.embeddings.create(model=AZURE_EMBED_DEPLOYMENT, input=[chunk_text])\\n    q = _l2_normalize(np.array([emb.data[0].embedding], dtype=np.float32))\\n    sims = DEMAND_EMB @ q[0]\\n    idx = np.argsort(-sims)[:k]\\n    return [DEMANDS[i] for i in idx]\\n\\ndef _llm_classify_chunk(chunk_id: str, chunk_text: str, candidates: List[Dict[str, str]]) -> Dict[str, Any]:\\n    if client is None:\\n        return {\"chunkId\": chunk_id, \"demandIds\": [], \"explanation\": \"AzureOpenAI client not initialized.\"}\\n    if not candidates:\\n        return {\"chunkId\": chunk_id, \"demandIds\": [], \"explanation\": \"No candidates from retrieval.\"}\\n\\n    demands_context = \"\\\\n\".join(\\n        [f\"- id: {d[\\'id\\']}\\\\n  name: {d[\\'name\\']}\\\\n  clarification: {d[\\'description\\']}\" for d in candidates]\\n    )\\n\\n    system = (\\n        \"You label customer requirements in product documentation. \"\\n        \"You MUST only choose from the provided demands. \"\\n        \"Match ONLY when the chunk clearly satisfies the demand\\'s clarification. \"\\n        \"Return at most 3 demands. \"\\n        \"If nothing matches, return an empty demandIds array. \"\\n        \"Probabilities must be in [0.0, 1.0]. \"\\n        \"Return JSON only.\"\\n    )\\n\\n    user = f\"\"\"Demands (id, name, clarification):\\n{demands_context}\\n\\nChunkId: {chunk_id}\\nChunk text:\\n{chunk_text}\\n\\nReturn JSON in this format exactly:\\n{{\\n  \"chunkId\": \"{chunk_id}\",\\n  \"demandIds\": [{{\"id\":\"<one of provided ids>\",\"probability\":0.85}}],\\n  \"explanation\": \"brief reason\"\\n}}\"\"\".strip()\\n\\n    resp = client.chat.completions.create(\\n        model=AZURE_CHAT_DEPLOYMENT,\\n        messages=[{\"role\": \"system\", \"content\": system}, {\"role\": \"user\", \"content\": user}],\\n    )\\n    content = resp.choices[0].message.content or \"\"\\n    parsed = _safe_json_loads(content)\\n    return parsed or {\"chunkId\": chunk_id, \"demandIds\": [], \"explanation\": \"LLM returned non-JSON.\"}\\n\\ndef run(raw_data: Any) -> Dict[str, Any]:\\n    request = json.loads(raw_data) if isinstance(raw_data, str) else raw_data\\n    if not isinstance(request, dict):\\n        raise ValueError(\"Request must be a JSON object/dict.\")\\n    if \"document\" not in request or \"num_preds\" not in request:\\n        raise ValueError(\"Invalid input: expected \\'document\\' and \\'num_preds\\'.\")\\n\\n    document = request[\"document\"]\\n    num_pred = int(request[\"num_preds\"])\\n\\n    by_id = document.get(\"contentDomain\", {}).get(\"byId\", {})\\n    if not isinstance(by_id, dict):\\n        raise ValueError(\"document.contentDomain.byId must be an object/dict.\")\\n\\n    document_demand_predictions = set()\\n\\n    for chunk_id, content in by_id.items():\\n        text = str(content.get(\"text\", \"\") or \"\")[:MAX_TEXT_CHARS]\\n\\n        if client is None or DEMAND_EMB is None or not DEMANDS:\\n            content.update({\"relevantProba\": 0.0, \"cdLogregPredictions\": [], \"cdTransformerPredictions\": []})\\n            continue\\n\\n        candidates = _retrieve_candidates(text, TOP_K_RAG)\\n        llm_out = _llm_classify_chunk(chunk_id, text, candidates)\\n\\n        preds = []\\n        for item in (llm_out.get(\"demandIds\", []) or [])[:MAX_LABELS_PER_CHUNK]:\\n            did = str(item.get(\"id\", \"\")).strip()\\n            proba = _safe_float(item.get(\"probability\", 0.0))\\n            if did and proba >= MIN_KEEP_PROBA:\\n                preds.append({\"label\": did, \"proba\": proba})\\n                document_demand_predictions.add(did)\\n\\n        preds = sorted(preds, key=lambda x: x[\"proba\"], reverse=True)[:num_pred]\\n        relevant_proba = max([p[\"proba\"] for p in preds], default=0.0)\\n\\n        content.update({\"relevantProba\": relevant_proba, \"cdLogregPredictions\": [], \"cdTransformerPredictions\": preds})\\n\\n    document[\"documentDemandPredictions\"] = list(document_demand_predictions)\\n    return {\"predictions\": document}\\n', encoding=\"utf-8\")\n",
        "print(\"Wrote:\", score_path, \"bytes:\", score_path.stat().st_size)\n",
        "\n",
        "# Minimalny plik testowy request\n",
        "sample_request = {\n",
        "  \"chunkId\": \"c1\",\n",
        "  \"text\": \"The motor frame shall be connected to protective earth (PE). The enclosure shall be at least IP55.\"\n",
        "}\n",
        "(Path(\"./sample_request.json\")).write_text(__import__(\"json\").dumps(sample_request, indent=2), encoding=\"utf-8\")\n",
        "print(\"Wrote: sample_request.json\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Po\u0142\u0105czenie do Azure ML (SDK v2) + sanity check istniej\u0105cego endpointu\n",
        "\n",
        "Je\u017celi tu jest problem, to najcz\u0119\u015bciej:\n",
        "- brak zalogowania (credential),\n",
        "- z\u0142y subscription/RG/workspace,\n",
        "- brak uprawnie\u0144.\n",
        "\n",
        "W przypadku b\u0142\u0119d\u00f3w wypiszemy konkret: error code + message.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.core.exceptions import HttpResponseError\n",
        "\n",
        "credential = DefaultAzureCredential(exclude_interactive_browser_credential=False)\n",
        "\n",
        "ml_client = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=SUBSCRIPTION_ID,\n",
        "    resource_group_name=RESOURCE_GROUP,\n",
        "    workspace_name=WORKSPACE_NAME\n",
        ")\n",
        "\n",
        "try:\n",
        "    endpoint = ml_client.online_endpoints.get(name=ENDPOINT_NAME)\n",
        "    print(\"Endpoint FOUND:\", endpoint.name)\n",
        "    print(\"  auth_mode:\", endpoint.auth_mode)\n",
        "    print(\"  scoring_uri:\", endpoint.scoring_uri)\n",
        "    print(\"  traffic:\", endpoint.traffic)\n",
        "except HttpResponseError as e:\n",
        "    print(\"FAILED to get endpoint. Details:\")\n",
        "    print(\"status:\", getattr(e, \"status_code\", None))\n",
        "    print(\"error:\", e)\n",
        "    raise\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Lista deployment\u00f3w pod endpointem + podstawowa diagnostyka\n",
        "\n",
        "Je\u015bli endpoint istnieje, ale deployment\u00f3w nie wida\u0107, zwykle oznacza:\n",
        "- inny workspace ni\u017c my\u015blisz,\n",
        "- brak uprawnie\u0144 do read na deployments.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "deployments = list(ml_client.online_deployments.list(endpoint_name=ENDPOINT_NAME))\n",
        "print(\"Deployments under endpoint:\", len(deployments))\n",
        "for d in deployments:\n",
        "    print(\"-\", d.name, \"| instance:\", getattr(d, \"instance_type\", None), \"| state:\", getattr(d, \"provisioning_state\", None))\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Utw\u00f3rz/od\u015bwie\u017c Environment asset z `conda_env.yml`\n",
        "\n",
        "To pozwala wykry\u0107 b\u0142\u0119dy typu:\n",
        "- brak paczki,\n",
        "- konflikt wersji,\n",
        "- z\u0142y format conda YAML.\n",
        "\n",
        "Je\u015bli build \u015brodowiska si\u0119 wywala, ten krok jest kluczowy.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from azure.ai.ml.entities import Environment\n",
        "\n",
        "env = Environment(\n",
        "    name=ENV_NAME,\n",
        "    version=ENV_VERSION,\n",
        "    description=\"Env for Azure ML online deployment calling Azure OpenAI via openai SDK\",\n",
        "    conda_file=str(CONDA_YAML_PATH),\n",
        "    image=\"mcr.microsoft.com/azureml/minimal-ubuntu22.04-py310-cpu-inference:latest\"\n",
        ")\n",
        "\n",
        "try:\n",
        "    env_result = ml_client.environments.create_or_update(env)\n",
        "    print(\"Environment registered:\", env_result.name, env_result.version)\n",
        "except HttpResponseError as e:\n",
        "    print(\"FAILED to create/update environment.\")\n",
        "    print(\"status:\", getattr(e, \"status_code\", None))\n",
        "    print(\"error:\", e)\n",
        "    raise\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) (Opcjonalnie) Usu\u0144 istniej\u0105cy deployment o tej samej nazwie\n",
        "\n",
        "To jest bezpieczna opcja na \u201ezamro\u017cone\u201d deploymenty / konflikty.\n",
        "Je\u017celi nie chcesz usuwa\u0107, ustaw `DELETE_EXISTING=False`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from azure.core.exceptions import ResourceNotFoundError\n",
        "\n",
        "DELETE_EXISTING = True\n",
        "\n",
        "if DELETE_EXISTING:\n",
        "    try:\n",
        "        ml_client.online_deployments.get(name=NEW_DEPLOYMENT_NAME, endpoint_name=ENDPOINT_NAME)\n",
        "        print(\"Deployment exists -> deleting:\", NEW_DEPLOYMENT_NAME)\n",
        "        poller = ml_client.online_deployments.begin_delete(name=NEW_DEPLOYMENT_NAME, endpoint_name=ENDPOINT_NAME)\n",
        "        poller.result()\n",
        "        print(\"Deleted:\", NEW_DEPLOYMENT_NAME)\n",
        "    except ResourceNotFoundError:\n",
        "        print(\"Deployment not found -> nothing to delete.\")\n",
        "    except HttpResponseError as e:\n",
        "        print(\"FAILED to delete deployment.\")\n",
        "        print(\"status:\", getattr(e, \"status_code\", None))\n",
        "        print(\"error:\", e)\n",
        "        raise\n",
        "else:\n",
        "    print(\"Skipping delete.\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9) Utw\u00f3rz nowy Managed Online Deployment (ten, kt\u00f3ry ma dosta\u0107 100% traffic)\n",
        "\n",
        "Uwaga: tutaj najcz\u0119\u015bciej \u201epada\u201d na:\n",
        "- build image (conda),\n",
        "- brak dost\u0119pu do ACR,\n",
        "- problem w `score.py` (np. importy),\n",
        "- brak plik\u00f3w w `code_configuration`.\n",
        "\n",
        "Po utworzeniu deploymentu od razu pobierzemy logi.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from azure.ai.ml.entities import ManagedOnlineDeployment, CodeConfiguration\n",
        "\n",
        "deployment = ManagedOnlineDeployment(\n",
        "    name=NEW_DEPLOYMENT_NAME,\n",
        "    endpoint_name=ENDPOINT_NAME,\n",
        "    environment=f\"{ENV_NAME}:{ENV_VERSION}\",\n",
        "    code_configuration=CodeConfiguration(code=str(CODE_DIR), scoring_script=\"score.py\"),\n",
        "    instance_type=INSTANCE_TYPE,\n",
        "    instance_count=INSTANCE_COUNT,\n",
        "    # Wszelkie env vars do score.py (Azure OpenAI) zostawiamy do konfiguracji na deployment\n",
        "    # Ustaw je w AML UI albo tutaj w dict. Bez tego init() w score.py si\u0119 wywali.\n",
        "    environment_variables={\n",
        "        # Azure OpenAI\n",
        "        \"AZURE_OPENAI_ENDPOINT\": os.getenv(\"AZURE_OPENAI_ENDPOINT\",\"\"),\n",
        "        \"AZURE_OPENAI_API_KEY\": os.getenv(\"AZURE_OPENAI_API_KEY\",\"\"),\n",
        "        \"AZURE_OPENAI_API_VERSION\": os.getenv(\"AZURE_OPENAI_API_VERSION\",\"2024-02-01\"),\n",
        "        \"AZURE_OPENAI_CHAT_DEPLOYMENT\": os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT\",\"\"),\n",
        "        \"AZURE_OPENAI_EMBED_DEPLOYMENT\": os.getenv(\"AZURE_OPENAI_EMBED_DEPLOYMENT\",\"\"),\n",
        "        # scoring tweaks\n",
        "        \"TOP_K_RAG\": os.getenv(\"TOP_K_RAG\",\"6\"),\n",
        "        \"MAX_LABELS_PER_CHUNK\": os.getenv(\"MAX_LABELS_PER_CHUNK\",\"3\"),\n",
        "        \"MIN_KEEP_PROBA\": os.getenv(\"MIN_KEEP_PROBA\",\"0.25\"),\n",
        "        \"MAX_TEXT_CHARS\": os.getenv(\"MAX_TEXT_CHARS\",\"8000\"),\n",
        "    }\n",
        ")\n",
        "\n",
        "try:\n",
        "    poller = ml_client.online_deployments.begin_create_or_update(deployment)\n",
        "    dep_result = poller.result()\n",
        "    print(\"Deployment created:\", dep_result.name, \"| state:\", dep_result.provisioning_state)\n",
        "except HttpResponseError as e:\n",
        "    print(\"FAILED to create/update deployment.\")\n",
        "    print(\"status:\", getattr(e, \"status_code\", None))\n",
        "    print(\"error:\", e)\n",
        "    # Spr\u00f3buj logi nawet je\u015bli create si\u0119 wywali\u0142 (czasem ju\u017c istniej\u0105 artefakty)\n",
        "    raise\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10) Logi deploymentu (je\u015bli co\u015b nie dzia\u0142a, to jest pierwszy \u201ego-to\u201d)\n",
        "\n",
        "Je\u017celi init() rzuca wyj\u0105tek (np. brakuje env var\u00f3w OpenAI), zobaczysz to tutaj.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "try:\n",
        "    logs = ml_client.online_deployments.get_logs(\n",
        "        name=NEW_DEPLOYMENT_NAME,\n",
        "        endpoint_name=ENDPOINT_NAME,\n",
        "        lines=200\n",
        "    )\n",
        "    print(logs)\n",
        "except HttpResponseError as e:\n",
        "    print(\"FAILED to get logs.\")\n",
        "    print(\"status:\", getattr(e, \"status_code\", None))\n",
        "    print(\"error:\", e)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11) Smoke test \u2014 wywo\u0142anie endpointu\n",
        "\n",
        "Wariant A: `ml_client.online_endpoints.invoke(...)` (je\u015bli dost\u0119pne w Twojej wersji SDK).\n",
        "Wariant B: bezpo\u015bredni `requests.post()` na `scoring_uri` + key z `get_keys()`.\n",
        "\n",
        "Je\u015bli smoke test nie przechodzi, **NIE przestawiamy trafficu**.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import json, requests\n",
        "from azure.core.exceptions import HttpResponseError\n",
        "\n",
        "# pobierz key (dzia\u0142a, je\u015bli endpoint auth_mode=key)\n",
        "try:\n",
        "    keys = ml_client.online_endpoints.get_keys(name=ENDPOINT_NAME)\n",
        "    primary_key = keys.primary_key\n",
        "    print(\"Got endpoint key (primary):\", \"OK\" if primary_key else \"EMPTY\")\n",
        "except HttpResponseError as e:\n",
        "    primary_key = None\n",
        "    print(\"Could not get keys (maybe aml_token auth). Error:\", e)\n",
        "\n",
        "endpoint = ml_client.online_endpoints.get(name=ENDPOINT_NAME)\n",
        "scoring_uri = endpoint.scoring_uri\n",
        "headers = {\"Content-Type\": \"application/json\"}\n",
        "if primary_key:\n",
        "    headers[\"Authorization\"] = f\"Bearer {primary_key}\"\n",
        "\n",
        "payload = json.loads(Path(\"sample_request.json\").read_text(encoding=\"utf-8\"))\n",
        "\n",
        "print(\"Calling scoring_uri:\", scoring_uri)\n",
        "resp = requests.post(scoring_uri, headers=headers, json=payload, timeout=120)\n",
        "print(\"Status:\", resp.status_code)\n",
        "print(resp.text[:2000])\n",
        "resp.raise_for_status()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12) Przestawienie trafficu \u2014 konfigurowalne (bez hardcode)\n",
        "\n",
        "Zasada:\n",
        "- Ustawiamy traffic dopiero po udanym smoke te\u015bcie.\n",
        "- Traffic to zwyk\u0142y dict `{deployment_name: percent}`. \ue200cite\ue202turn0search3\ue201\n",
        "\n",
        "Wa\u017cne: to aktualizuje **endpoint** (nie deployment).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from azure.ai.ml.entities import ManagedOnlineEndpoint\n",
        "\n",
        "def set_traffic(traffic: dict):\n",
        "    ep = ml_client.online_endpoints.get(name=ENDPOINT_NAME)\n",
        "    ep.traffic = traffic\n",
        "    poller = ml_client.online_endpoints.begin_create_or_update(ep)\n",
        "    result = poller.result()\n",
        "    return result\n",
        "\n",
        "if SET_TRAFFIC_AFTER_SMOKE_TEST:\n",
        "    traffic = {NEW_DEPLOYMENT_NAME: NEW_DEPLOYMENT_TRAFFIC_PERCENT}\n",
        "    # Je\u015bli nie ustawiasz 100%, mo\u017cesz dopisa\u0107 pozosta\u0142e deploymenty r\u0119cznie:\n",
        "    # traffic = {NEW_DEPLOYMENT_NAME: 70, \"old_blue\": 30}\n",
        "    updated = set_traffic(traffic)\n",
        "    print(\"Updated traffic:\", updated.traffic)\n",
        "else:\n",
        "    print(\"Skipping traffic update (SET_TRAFFIC_AFTER_SMOKE_TEST=False).\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13) Kontrola ko\u0144cowa: endpoint traffic + lista deployment\u00f3w\n",
        "\n",
        "Je\u015bli w UI masz \u201ezamro\u017cone\u201d suwaki trafficu, zwykle znaczy, \u017ce UI blokuje edycj\u0119 w pewnych stanach,\n",
        "ale SDK/CLI nadal powinny pozwoli\u0107 na update `endpoint.traffic`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "endpoint = ml_client.online_endpoints.get(name=ENDPOINT_NAME)\n",
        "print(\"Final traffic:\", endpoint.traffic)\n",
        "\n",
        "deployments = list(ml_client.online_deployments.list(endpoint_name=ENDPOINT_NAME))\n",
        "print(\"Deployments:\")\n",
        "for d in deployments:\n",
        "    print(\"-\", d.name, \"| state:\", getattr(d, \"provisioning_state\", None))\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}