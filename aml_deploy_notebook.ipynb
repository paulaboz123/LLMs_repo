{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Azure ML Online Endpoint – Deploy/Update notebook (single-endpoint, single-deployment)\n\nCel: **podmiana deploymentu** na istniejącym Azure ML Online Endpoint tak, aby aplikacja trafiała w właściwy deployment (nagłówek `azureml-model-deployment`).\n\nNotebook robi:\n1. Konfiguracja i logowanie do workspace\n2. Weryfikacja endpointu i istniejących deploymentów\n3. **Hard reset**: usuń deployment (jeśli istnieje) – usuwa konflikty `StartUpdateDeploymentAsync`\n4. Utworzenie środowiska (environment) i deploymentu\n5. Ustawienie traffic allocation\n6. Test `invoke` + podgląd logów\n\n> Zastąp wartości w sekcji **CONFIG**. Nie zmieniaj nazw pól w payload – są dostosowane do Twojej aplikacji.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# 0) (opcjonalnie) Zainstaluj zależności – uruchom raz w nowym środowisku\n# !pip -q install \"azure-ai-ml>=1.16.0\" \"azure-identity>=1.16.0\" \"azure-core>=1.30.0\"\n# !pip -q install \"requests>=2.31.0\"\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1) CONFIG – UZUPEŁNIJ"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# === AML WORKSPACE ===\nSUBSCRIPTION_ID = \"<SUBSCRIPTION_ID>\"\nRESOURCE_GROUP  = \"<RESOURCE_GROUP>\"\nWORKSPACE_NAME  = \"<WORKSPACE_NAME>\"\n\n# === AML ONLINE ENDPOINT ===\nENDPOINT_NAME   = \"<EXISTING_ONLINE_ENDPOINT_NAME>\"\n\n# === DEPLOYMENT NAME (MUSI PASOWAĆ DO NAGŁÓWKA Z APKI) ===\n# Apka wysyła: azureml-model-deployment: albot-{modelLower}-model\nDEPLOYMENT_NAME = \"<albot-xxx-model>\"\n\n# === MODELNAME wysyłany przez apkę (do testów invoke) ===\nAPP_MODEL_NAME  = \"<WheShe_or_other>\"\n\n# === DOCKER / ENV ===\nIMAGE_URI       = \"<YOUR_IMAGE_URI>\"\nINFERENCE_PORT  = 5001\n\n# === Azure OpenAI ENV VARS (w kontenerze) ===\nAZURE_OPENAI_ENDPOINT = \"https://<your-aoai-resource>.openai.azure.com/\"\nAZURE_OPENAI_API_KEY  = \"<your-aoai-key>\"\nAZURE_OPENAI_API_VERSION = \"2024-12-01-preview\"\n\n# CHAT_DEPLOYMENT: NAZWA deploymentu w Azure OpenAI (Portal -> Azure OpenAI -> Deployments -> 'Deployment name')\nCHAT_DEPLOYMENT = \"<gpt-5-mini>\"\n\n# (opcjonalnie) embeddings, jeśli Twój score.py tego wymaga\nAZURE_OPENAI_EMBEDDINGS_DEPLOYMENT = \"<text-embedding-3-small-or-other>\"  # lub \"\"\n\n# === Compute/instance ===\nINSTANCE_TYPE = \"Standard_DS3_v2\"\nINSTANCE_COUNT = 1\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2) Połączenie z AML + sanity check endpointu"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from azure.ai.ml import MLClient\nfrom azure.identity import DefaultAzureCredential\nfrom azure.core.exceptions import ResourceNotFoundError\nimport json\n\ncredential = DefaultAzureCredential(exclude_interactive_browser_credential=False)\nml_client = MLClient(credential, SUBSCRIPTION_ID, RESOURCE_GROUP, WORKSPACE_NAME)\n\nendpoint = ml_client.online_endpoints.get(ENDPOINT_NAME)\nprint(\"Endpoint:\", endpoint.name)\nprint(\"State:\", endpoint.provisioning_state, \"| Auth:\", endpoint.auth_mode)\n\nprint(\"\\nDeployments on endpoint:\")\nfor d in ml_client.online_deployments.list(endpoint_name=ENDPOINT_NAME):\n    print(\"-\", d.name, \"| state:\", d.provisioning_state)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3) Hard reset deploymentu (usuń jeśli istnieje) – usuwa Conflict/locki"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from azure.core.exceptions import HttpResponseError\n\ndef delete_deployment_if_exists():\n    try:\n        ml_client.online_deployments.get(name=DEPLOYMENT_NAME, endpoint_name=ENDPOINT_NAME)\n    except ResourceNotFoundError:\n        print(\"Deployment does not exist:\", DEPLOYMENT_NAME)\n        return\n\n    print(\"Deleting deployment:\", DEPLOYMENT_NAME)\n    ml_client.online_deployments.begin_delete(\n        name=DEPLOYMENT_NAME,\n        endpoint_name=ENDPOINT_NAME\n    ).result()\n    print(\"Deleted.\")\n\ndelete_deployment_if_exists()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4) Utwórz deployment (Managed Online Deployment)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from azure.ai.ml.entities import ManagedOnlineDeployment, Environment\n\nenv = Environment(\n    name=f\"{DEPLOYMENT_NAME}-env\",\n    image=IMAGE_URI\n)\n\nenv_vars = {\n    \"AZURE_OPENAI_ENDPOINT\": AZURE_OPENAI_ENDPOINT,\n    \"AZURE_OPENAI_API_KEY\": AZURE_OPENAI_API_KEY,\n    \"AZURE_OPENAI_API_VERSION\": AZURE_OPENAI_API_VERSION,\n    \"CHAT_DEPLOYMENT\": CHAT_DEPLOYMENT,\n}\n\nif AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT and AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT.strip():\n    env_vars[\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\"] = AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\n\ndeployment = ManagedOnlineDeployment(\n    name=DEPLOYMENT_NAME,\n    endpoint_name=ENDPOINT_NAME,\n    environment=env,\n    instance_type=INSTANCE_TYPE,\n    instance_count=INSTANCE_COUNT,\n    environment_variables=env_vars,\n)\n\nprint(\"Creating/Updating deployment:\", DEPLOYMENT_NAME)\npoller = ml_client.online_deployments.begin_create_or_update(deployment)\ndep = poller.result()\nprint(\"Provisioning state:\", dep.provisioning_state)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5) Ustaw traffic allocation (100% do nowego deploymentu)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "endpoint = ml_client.online_endpoints.get(ENDPOINT_NAME)\nendpoint.traffic = {DEPLOYMENT_NAME: 100}\nml_client.online_endpoints.begin_create_or_update(endpoint).result()\nprint(\"Traffic:\", ml_client.online_endpoints.get(ENDPOINT_NAME).traffic)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 6) Debug: status + logi kontenera"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from azure.core.exceptions import HttpResponseError\n\ndef show_deployment_status_and_logs(lines=200):\n    d = ml_client.online_deployments.get(name=DEPLOYMENT_NAME, endpoint_name=ENDPOINT_NAME)\n    print(\"Deployment:\", d.name)\n    print(\"Provisioning:\", d.provisioning_state)\n    print(\"Instance:\", d.instance_type, \"x\", d.instance_count)\n\n    try:\n        logs = ml_client.online_deployments.get_logs(\n            name=DEPLOYMENT_NAME,\n            endpoint_name=ENDPOINT_NAME,\n            lines=lines\n        )\n        print(\"\\n--- LOGS (tail) ---\\n\")\n        print(logs)\n    except HttpResponseError as e:\n        print(\"Could not fetch logs:\", e)\n\nshow_deployment_status_and_logs(lines=400)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 7) Test invoke (payload jak w aplikacji)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "test_payload = {\n    \"document\": {\n        \"contentDomain\": {\"byId\": {}},\n        \"contextId\": \"test\",\n    },\n    \"model\": APP_MODEL_NAME,\n    \"num_preds\": 3\n}\n\ntry:\n    resp = ml_client.online_endpoints.invoke(\n        endpoint_name=ENDPOINT_NAME,\n        deployment_name=DEPLOYMENT_NAME,\n        request_file=None,\n        request_json=test_payload\n    )\n    print(\"Response:\")\n    print(resp)\nexcept Exception as e:\n    print(\"Invoke failed:\", repr(e))\n    show_deployment_status_and_logs(lines=600)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 8) Walidacja formatu odpowiedzi (czy apka zobaczy `documentDemandPredictions`)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "def validate_response_schema(resp_text: str):\n    try:\n        obj = json.loads(resp_text)\n    except Exception:\n        print(\"Response is not JSON.\")\n        return False\n\n    arr = None\n    if isinstance(obj, dict):\n        if \"predictions\" in obj and isinstance(obj[\"predictions\"], dict):\n            arr = obj[\"predictions\"].get(\"documentDemandPredictions\")\n        if arr is None:\n            arr = obj.get(\"documentDemandPredictions\")\n    ok = isinstance(arr, list)\n    print(\"Has documentDemandPredictions array:\", ok)\n    if ok and arr:\n        print(\"First item keys:\", list(arr[0].keys()))\n    return ok\n\n# Użycie:\n# validate_response_schema(resp)\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}