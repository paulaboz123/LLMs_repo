{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PoC (rozszerzony): Fine-tuning bi-encodera na parach (text, demand_desc) + klasyfikacja przez max cosine similarity\n",
        "\n",
        "Ten notebook robi:\n",
        "1) Wczytanie danych z CSV/XLSX (`text`, `demand_id`, `demand_desc`)\n",
        "2) Zbudowanie mapy `demand_id -> demand_desc` (prototypy klas)\n",
        "3) Split train/val/test na danych polabelowanych\n",
        "4) **Fine-tuning** bi-encodera (Sentence-Transformers) na parach:\n",
        "   - `query: <text>` ↔ `passage: <opis demandu>`\n",
        "   - loss: `MultipleNegativesRankingLoss` (in-batch negatives)\n",
        "5) Predykcja klasy: dla zdania wybieramy label z najwyższym cosine similarity do embeddingu opisów klas\n",
        "6) Ewaluacja (macro/micro F1) + zapis predykcji dla całego datasetu\n",
        "7) (Opcjonalnie) pseudo-labeling na unlabeled i druga krótka runda dotrenowania\n",
        "\n",
        "**Bez RAG, bez OpenAI.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "!pip -q install -U \"sentence-transformers>=3.0.0\" \"datasets>=2.20.0\" \"transformers>=4.41.0\" \\\n",
        "  \"accelerate>=0.30.0\" \"scikit-learn>=1.4.0\" \"pandas>=2.0.0\" \"numpy>=1.24.0\" \"tqdm\" \"openpyxl\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importy + konfiguracja"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "from sentence_transformers import SentenceTransformer, InputExample\n",
        "from sentence_transformers.util import cos_sim\n",
        "from sentence_transformers.losses import MultipleNegativesRankingLoss\n",
        "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
        "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
        "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Wczytanie danych (CSV lub XLSX)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "DATA_PATH = \"dataset.csv\"  # albo: \"dataset.xlsx\"\n",
        "\n",
        "if DATA_PATH.lower().endswith(\".xlsx\"):\n",
        "    df = pd.read_excel(DATA_PATH)\n",
        "else:\n",
        "    df = pd.read_csv(DATA_PATH)\n",
        "\n",
        "required_cols = {\"text\", \"demand_id\", \"demand_desc\"}\n",
        "missing = required_cols - set(df.columns)\n",
        "if missing:\n",
        "    raise ValueError(f\"Brak wymaganych kolumn: {missing}\")\n",
        "\n",
        "df[\"text\"] = df[\"text\"].astype(str)\n",
        "df[\"demand_id\"] = df[\"demand_id\"].replace(\"\", np.nan)\n",
        "\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"Labeled:\", df[\"demand_id\"].notna().sum(), \"Unlabeled:\", df[\"demand_id\"].isna().sum())\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mapa: demand_id -> demand_desc (prototypy klas)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "labeled = df[df[\"demand_id\"].notna()].copy()\n",
        "unlabeled = df[df[\"demand_id\"].isna()].copy()\n",
        "\n",
        "label_desc = (\n",
        "    labeled[[\"demand_id\", \"demand_desc\"]]\n",
        "    .dropna()\n",
        "    .drop_duplicates(subset=[\"demand_id\"])\n",
        "    .set_index(\"demand_id\")[\"demand_desc\"]\n",
        "    .to_dict()\n",
        ")\n",
        "\n",
        "all_labels = sorted(label_desc.keys())\n",
        "print(\"Unique labeled classes:\", len(all_labels))\n",
        "\n",
        "missing_desc = set(labeled[\"demand_id\"].unique()) - set(label_desc.keys())\n",
        "print(\"Labels missing desc:\", len(missing_desc))\n",
        "if missing_desc:\n",
        "    print(\"Examples:\", list(missing_desc)[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split train/val/test\n",
        "\n",
        "W razie problemów ze stratyfikacją (rzadkie klasy) przechodzimy na split bez stratyfikacji."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "X = labeled[\"text\"].values\n",
        "y = labeled[\"demand_id\"].values\n",
        "\n",
        "def safe_stratified_split(X, y, test_size, seed):\n",
        "    try:\n",
        "        return train_test_split(X, y, test_size=test_size, random_state=seed, stratify=y)\n",
        "    except ValueError:\n",
        "        return train_test_split(X, y, test_size=test_size, random_state=seed, stratify=None)\n",
        "\n",
        "X_train, X_tmp, y_train, y_tmp = safe_stratified_split(X, y, test_size=0.30, seed=SEED)\n",
        "X_val, X_test, y_val, y_test = safe_stratified_split(X_tmp, y_tmp, test_size=0.50, seed=SEED)\n",
        "\n",
        "print(\"Train/Val/Test:\", len(X_train), len(X_val), len(X_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model bazowy (bi-encoder)\n",
        "\n",
        "Rekomendacja startowa:\n",
        "- `intfloat/multilingual-e5-base` (PL/EN)\n",
        "Alternatywy:\n",
        "- `sentence-transformers/paraphrase-multilingual-mpnet-base-v2`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "BASE_MODEL = \"intfloat/multilingual-e5-base\"\n",
        "model = SentenceTransformer(BASE_MODEL, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Budowa datasetu do fine-tuningu: pary (text, demand_desc)\n",
        "\n",
        "Dla każdego przykładu uczymy model mapować `text` blisko opisu właściwej klasy.\n",
        "Loss: `MultipleNegativesRankingLoss` – inne opisy w batchu stają się negatywami (bardzo skuteczne w klasyfikacji wieloklasowej)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def build_pairs(texts, labels, label_desc_map):\n",
        "    pairs = []\n",
        "    skipped = 0\n",
        "    for t, lab in zip(texts, labels):\n",
        "        desc = label_desc_map.get(lab)\n",
        "        if not isinstance(desc, str) or not desc.strip():\n",
        "            skipped += 1\n",
        "            continue\n",
        "        # E5: query/passage\n",
        "        pairs.append(InputExample(texts=[f\"query: {t}\", f\"passage: {desc}\"]))\n",
        "    return pairs, skipped\n",
        "\n",
        "train_pairs, sk_tr = build_pairs(X_train, y_train, label_desc)\n",
        "val_pairs, sk_va = build_pairs(X_val, y_val, label_desc)\n",
        "test_pairs, sk_te = build_pairs(X_test, y_test, label_desc)\n",
        "\n",
        "print(\"Train pairs:\", len(train_pairs), \"skipped:\", sk_tr)\n",
        "print(\"Val pairs:\", len(val_pairs), \"skipped:\", sk_va)\n",
        "print(\"Test pairs:\", len(test_pairs), \"skipped:\", sk_te)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fine-tuning\n",
        "\n",
        "Uwaga praktyczna:\n",
        "- przy 3k labeled, 2–4 epoki zwykle wystarczą\n",
        "- batch 16–64 zależnie od GPU RAM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "OUTPUT_DIR = \"./outputs/sbert_demand_desc_finetuned\"\n",
        "\n",
        "args = SentenceTransformerTrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=64,\n",
        "    learning_rate=2e-5,\n",
        "    warmup_ratio=0.1,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=250,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=250,\n",
        "    save_total_limit=2,\n",
        "    logging_steps=50,\n",
        "    seed=SEED,\n",
        ")\n",
        "\n",
        "loss = MultipleNegativesRankingLoss(model)\n",
        "\n",
        "# Evaluator: sprawdza czy embeddingi par (text, desc) są blisko\n",
        "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(val_pairs, name=\"val_pairs\")\n",
        "\n",
        "trainer = SentenceTransformerTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_pairs,\n",
        "    eval_dataset=val_pairs,\n",
        "    loss=loss,\n",
        "    evaluator=evaluator,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "model.save(OUTPUT_DIR)\n",
        "print(\"Saved fine-tuned model to:\", OUTPUT_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Klasyfikacja przez podobieństwo do opisów labeli (po fine-tuningu)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def embed_texts(st_model, texts, batch_size=128):\n",
        "    embs = []\n",
        "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Embedding\"):\n",
        "        batch = texts[i:i+batch_size]\n",
        "        embs.append(st_model.encode(batch, convert_to_tensor=True, normalize_embeddings=True))\n",
        "    return torch.cat(embs, dim=0)\n",
        "\n",
        "label_texts = [f\"passage: {label_desc[l]}\" for l in all_labels]\n",
        "label_emb = embed_texts(model, label_texts, batch_size=128)\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_labels(st_model, texts, label_emb, all_labels, batch_size=128):\n",
        "    preds = []\n",
        "    scores = []\n",
        "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Predict\"):\n",
        "        batch = [f\"query: {t}\" for t in texts[i:i+batch_size]]\n",
        "        text_emb = st_model.encode(batch, convert_to_tensor=True, normalize_embeddings=True)\n",
        "        sims = cos_sim(text_emb, label_emb)  # [B, L]\n",
        "        best = torch.argmax(sims, dim=1).cpu().numpy()\n",
        "        best_scores = torch.max(sims, dim=1).values.cpu().numpy()\n",
        "        preds.extend([all_labels[j] for j in best])\n",
        "        scores.extend(best_scores.tolist())\n",
        "    return np.array(preds), np.array(scores)\n",
        "\n",
        "val_pred, _ = predict_labels(model, X_val, label_emb, all_labels)\n",
        "test_pred, _ = predict_labels(model, X_test, label_emb, all_labels)\n",
        "\n",
        "print(\"VAL macro F1 :\", f1_score(y_val, val_pred, average=\"macro\"))\n",
        "print(\"VAL micro F1 :\", f1_score(y_val, val_pred, average=\"micro\"))\n",
        "print(\"TEST macro F1:\", f1_score(y_test, test_pred, average=\"macro\"))\n",
        "print(\"TEST micro F1:\", f1_score(y_test, test_pred, average=\"micro\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Raport (może być długi dla 150 klas)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "print(classification_report(y_test, test_pred, digits=3, zero_division=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (Opcjonalnie) Pseudo-labeling + druga runda dotrenowania (self-training)\n",
        "\n",
        "Cel: wykorzystać 30k unlabeled, ale tylko bardzo pewne predykcje.\n",
        "Mechanizm:\n",
        "- liczysz top1 i top2 podobieństwa\n",
        "- wybierasz wiersze gdzie:\n",
        "  - top1 >= THRESH\n",
        "  - oraz (top1 - top2) >= MARGIN (zmniejsza pomyłki między podobnymi klasami)\n",
        "- doklejasz te pary do train i robisz 1 epokę dotrenowania\n",
        "\n",
        "Jeśli nie chcesz self-training, pomiń tę sekcję."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "THRESH = 0.45\n",
        "MARGIN = 0.06\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_top2(st_model, texts, label_emb, all_labels, batch_size=128):\n",
        "    top1_label, top1_score, top2_score = [], [], []\n",
        "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Predict top2\"):\n",
        "        batch = [f\"query: {t}\" for t in texts[i:i+batch_size]]\n",
        "        text_emb = st_model.encode(batch, convert_to_tensor=True, normalize_embeddings=True)\n",
        "        sims = cos_sim(text_emb, label_emb)  # [B, L]\n",
        "        vals, idxs = torch.topk(sims, k=2, dim=1)\n",
        "        vals = vals.cpu().numpy()\n",
        "        idxs = idxs.cpu().numpy()\n",
        "        top1_label.extend([all_labels[j] for j in idxs[:,0]])\n",
        "        top1_score.extend(vals[:,0].tolist())\n",
        "        top2_score.extend(vals[:,1].tolist())\n",
        "    return np.array(top1_label), np.array(top1_score), np.array(top2_score)\n",
        "\n",
        "pseudo_pairs = []\n",
        "if len(unlabeled) > 0:\n",
        "    ul_texts = unlabeled[\"text\"].astype(str).tolist()\n",
        "    ul_pred, ul_s1, ul_s2 = predict_top2(model, ul_texts, label_emb, all_labels)\n",
        "    keep = (ul_s1 >= THRESH) & ((ul_s1 - ul_s2) >= MARGIN)\n",
        "\n",
        "    accepted = int(keep.sum())\n",
        "    print(\"Pseudo accepted:\", accepted, \"out of\", len(unlabeled))\n",
        "\n",
        "    if accepted > 0:\n",
        "        pseudo_texts = unlabeled.loc[keep, \"text\"].astype(str).values\n",
        "        pseudo_labels = ul_pred[keep]\n",
        "\n",
        "        pseudo_pairs, sk = build_pairs(pseudo_texts, pseudo_labels, label_desc)\n",
        "        print(\"Pseudo pairs built:\", len(pseudo_pairs), \"skipped:\", sk)\n",
        "else:\n",
        "    print(\"No unlabeled rows found.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Druga runda dotrenowania (1 epoka)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "if pseudo_pairs:\n",
        "    train_pairs_round2 = train_pairs + pseudo_pairs\n",
        "\n",
        "    args2 = SentenceTransformerTrainingArguments(\n",
        "        output_dir=OUTPUT_DIR + \"_round2\",\n",
        "        num_train_epochs=1,\n",
        "        per_device_train_batch_size=32,\n",
        "        per_device_eval_batch_size=64,\n",
        "        learning_rate=1e-5,\n",
        "        warmup_ratio=0.05,\n",
        "        fp16=torch.cuda.is_available(),\n",
        "        evaluation_strategy=\"steps\",\n",
        "        eval_steps=250,\n",
        "        save_strategy=\"steps\",\n",
        "        save_steps=250,\n",
        "        save_total_limit=2,\n",
        "        logging_steps=50,\n",
        "        seed=SEED,\n",
        "    )\n",
        "\n",
        "    trainer2 = SentenceTransformerTrainer(\n",
        "        model=model,\n",
        "        args=args2,\n",
        "        train_dataset=train_pairs_round2,\n",
        "        eval_dataset=val_pairs,\n",
        "        loss=MultipleNegativesRankingLoss(model),\n",
        "        evaluator=evaluator,\n",
        "    )\n",
        "    trainer2.train()\n",
        "    model.save(args2.output_dir)\n",
        "    print(\"Saved round2 model to:\", args2.output_dir)\n",
        "\n",
        "    # Recompute label embeddings\n",
        "    label_emb = embed_texts(model, label_texts, batch_size=128)\n",
        "\n",
        "    # Re-evaluate\n",
        "    val_pred, _ = predict_labels(model, X_val, label_emb, all_labels)\n",
        "    test_pred, _ = predict_labels(model, X_test, label_emb, all_labels)\n",
        "\n",
        "    print(\"After self-training\")\n",
        "    print(\"VAL macro F1 :\", f1_score(y_val, val_pred, average=\"macro\"))\n",
        "    print(\"VAL micro F1 :\", f1_score(y_val, val_pred, average=\"micro\"))\n",
        "    print(\"TEST macro F1:\", f1_score(y_test, test_pred, average=\"macro\"))\n",
        "    print(\"TEST micro F1:\", f1_score(y_test, test_pred, average=\"micro\"))\n",
        "else:\n",
        "    print(\"No pseudo pairs -> skipping round2.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Zapis predykcji dla całego datasetu (labeled + unlabeled)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "all_texts = df[\"text\"].astype(str).tolist()\n",
        "pred_all, score_all = predict_labels(model, all_texts, label_emb, all_labels)\n",
        "\n",
        "out = df.copy()\n",
        "out[\"pred_demand_id\"] = pred_all\n",
        "out[\"pred_score\"] = score_all\n",
        "\n",
        "OUT_PATH = \"predictions.parquet\"\n",
        "out.to_parquet(OUT_PATH, index=False)\n",
        "\n",
        "print(\"Saved:\", OUT_PATH)\n",
        "out.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Wskazówki strojenia\n",
        "\n",
        "- Jeśli self-training psuje wyniki: podnieś `THRESH` / `MARGIN` lub wyłącz sekcję.\n",
        "- Jeśli bierze za mało pseudo-labeli: obniż `THRESH` lub `MARGIN`, ale obserwuj F1.\n",
        "- Jeśli masz bardzo podobne labelki: zwiększ batch size (więcej negatywów w batchu) i rozważ 4 epoki.\n",
        "- Jeżeli Twoje teksty są długie: rozważ wcześniejsze cięcie do 1–2 zdań (ale pisałaś, że czyszczenie/format jest zrobione)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}