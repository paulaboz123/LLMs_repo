import os
import json
import time
import math
import logging
from typing import Dict, Any, List, Tuple

import numpy as np
import pandas as pd
from openai import AzureOpenAI

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("demand-labeler")

# Globals initialized in init()
CLIENT: AzureOpenAI = None
EMBED_DEPLOYMENT: str = None
DEMANDS: List[Dict[str, str]] = []
DEMAND_EMB: np.ndarray = None  # shape (N, D)

# -----------------------------
# Utilities
# -----------------------------
def _safe_float(x, default=0.0) -> float:
    try:
        return float(x)
    except Exception:
        return float(default)

def _cosine_sim_matrix(query_vec: np.ndarray, mat: np.ndarray) -> np.ndarray:
    # query_vec shape (D,), mat shape (N,D)
    q = query_vec / (np.linalg.norm(query_vec) + 1e-12)
    m = mat / (np.linalg.norm(mat, axis=1, keepdims=True) + 1e-12)
    return m @ q  # (N,)

def _sim_to_proba(sim: float) -> float:
    """
    Convert cosine similarity [-1..1] to a pseudo-probability [0..1].
    Tunable. This is deterministic and monotonic.
    """
    # shift to [0..1]
    s = (sim + 1.0) / 2.0
    # sharpen a bit (optional)
    s = s ** 2
    return max(0.0, min(1.0, float(s)))

def _pick_content_store(document: Dict[str, Any]) -> Tuple[str, Dict[str, Any]]:
    """
    Returns (store_name, byId_dict) from either:
      - document["contentDomain"]["byId"]
      - document["content"]["byId"]
    """
    for store_name in ("contentDomain", "content"):
        node = document.get(store_name)
        if isinstance(node, dict) and isinstance(node.get("byId"), dict):
            return store_name, node["byId"]
    raise ValueError("Cannot find content store. Expected document.contentDomain.byId or document.content.byId")

def _get_embedding(texts: List[str]) -> List[List[float]]:
    # Embeddings API in Azure OpenAI python SDK
    # Keep it simple: one request for many inputs (works for most deployments).
    resp = CLIENT.embeddings.create(model=EMBED_DEPLOYMENT, input=texts)
    # Ensure order preserved
    return [d.embedding for d in resp.data]

def _load_demands_xlsx(path: str) -> List[Dict[str, str]]:
    df = pd.read_excel(path)
    expected = {"demand_id", "demand", "description"}
    cols = set([c.strip() for c in df.columns])
    missing = expected - cols
    if missing:
        raise ValueError(f"demands.xlsx missing columns: {sorted(list(missing))}. Found: {sorted(list(cols))}")

    # normalize column names if needed
    df = df.rename(columns={c: c.strip() for c in df.columns})

    demands = []
    for _, row in df.iterrows():
        did = str(row["demand_id"]).strip()
        dname = str(row["demand"]).strip()
        ddesc = str(row["description"]).strip() if not pd.isna(row["description"]) else ""
        if not did or did.lower() == "nan":
            continue
        demands.append({"id": did, "demand": dname, "description": ddesc})
    if not demands:
        raise ValueError("demands.xlsx loaded but resulted in 0 demands (check demand_id values).")
    return demands

def _build_demand_text(d: Dict[str, str]) -> str:
    # what we embed for each label
    # include both demand name and description
    demand = d.get("demand", "").strip()
    desc = d.get("description", "").strip()
    if desc:
        return f"{demand}\n{desc}"
    return demand

def _predict_for_text(text: str, top_k: int = 3, min_proba: float = 0.55) -> List[Dict[str, Any]]:
    """
    Returns list like [{"label": demand_id, "proba": 0.87}, ...]
    """
    text = (text or "").strip()
    if len(text) < 3:
        return []

    q_emb = np.array(_get_embedding([text])[0], dtype=np.float32)
    sims = _cosine_sim_matrix(q_emb, DEMAND_EMB)
    idx = np.argsort(-sims)[: max(1, int(top_k))]

    preds = []
    for i in idx:
        proba = _sim_to_proba(float(sims[i]))
        if proba >= float(min_proba):
            preds.append({"label": DEMANDS[int(i)]["id"], "proba": float(round(proba, 4))})

    # sort by proba desc
    preds.sort(key=lambda x: x["proba"], reverse=True)
    return preds

# -----------------------------
# Azure ML entrypoints
# -----------------------------
def init():
    global CLIENT, EMBED_DEPLOYMENT, DEMANDS, DEMAND_EMB

    logger.info("Initializing demand labeler...")

    # Azure OpenAI env
    azure_endpoint = os.environ.get("AZURE_OPENAI_ENDPOINT", "").strip()
    api_key = os.environ.get("AZURE_OPENAI_API_KEY", "").strip()
    api_version = os.environ.get("AZURE_OPENAI_API_VERSION", "").strip()
    EMBED_DEPLOYMENT = os.environ.get("AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT", "").strip()

    if not azure_endpoint or not api_key or not api_version or not EMBED_DEPLOYMENT:
        raise RuntimeError(
            "Missing env vars. Required: AZURE_OPENAI_ENDPOINT, AZURE_OPENAI_API_KEY, "
            "AZURE_OPENAI_API_VERSION, AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT"
        )

    CLIENT = AzureOpenAI(
        azure_endpoint=azure_endpoint,
        api_key=api_key,
        api_version=api_version,
    )

    # Locate demands.xlsx
    # In AML, you typically bundle it in the code folder. Keep it next to score.py.
    base_dir = os.path.dirname(os.path.abspath(__file__))
    demands_path = os.environ.get("DEMANDS_XLSX_PATH", os.path.join(base_dir, "demands.xlsx"))

    DEMANDS = _load_demands_xlsx(demands_path)
    logger.info("Loaded %d demands from %s", len(DEMANDS), demands_path)

    # Precompute embeddings for all demands (fast inference later)
    demand_texts = [_build_demand_text(d) for d in DEMANDS]
    emb = _get_embedding(demand_texts)
    DEMAND_EMB = np.array(emb, dtype=np.float32)

    logger.info("Initialized successfully. Demand embedding matrix shape=%s", DEMAND_EMB.shape)


def run(raw_data):
    """
    Expects raw_data to be JSON string or dict. We handle both.
    Must return a JSON-serializable object.
    """
    start = time.time()

    try:
        if raw_data is None:
            return {"error": "Empty request body (raw_data is None)"}

        if isinstance(raw_data, (bytes, bytearray)):
            raw_data = raw_data.decode("utf-8", errors="replace")

        if isinstance(raw_data, str):
            raw_data = raw_data.strip()
            if not raw_data:
                return {"error": "Empty request body (raw_data is empty string)"}
            try:
                request_data = json.loads(raw_data)
            except json.JSONDecodeError as e:
                return {"error": "Invalid JSON", "detail": str(e)}
        elif isinstance(raw_data, dict):
            request_data = raw_data
        else:
            return {"error": f"Unsupported request type: {type(raw_data)}"}

        # IMPORTANT: your old score.py likely expected {"document": <dict>, "num_preds": <int>}
        # but sometimes AML/app sends the document directly. Support both.
        if "document" in request_data:
            document = request_data["document"]
        else:
            document = request_data

        num_pred = int(request_data.get("num_preds", request_data.get("numPreds", 3)) or 3)

        if not isinstance(document, dict):
            return {"error": "Invalid 'document' type", "detail": f"Expected dict, got {type(document)}"}

        store_name, by_id = _pick_content_store(document)
        logger.info("Using store=%s with %d items", store_name, len(by_id))

        # Per-content predictions
        doc_demand_ids = set()

        # NOTE: iterate in stable order (dict order in Python is insertion order)
        for _, content in by_id.items():
            if not isinstance(content, dict):
                continue
            text = content.get("text")
            if not isinstance(text, str) or not text.strip():
                # still ensure keys exist to avoid frontend assumptions
                content.setdefault("cdTransformerPredictions", [])
                continue

            preds = _predict_for_text(text, top_k=num_pred, min_proba=0.55)

            # This is the key contract: label MUST be demand_id
            content["cdTransformerPredictions"] = preds

            # Optional: if your UI expects these keys to exist (safe defaults)
            content.setdefault("relevantProba", 1.0 if preds else 0.0)
            content.setdefault("cdLogregPredictions", [])

            for p in preds:
                doc_demand_ids.add(p["label"])

        # Document-level field (old code used a set -> list)
        document["documentDemandPredictions"] = sorted(list(doc_demand_ids))

        latency = round(time.time() - start, 3)
        logger.info("Completed scoring in %ss, doc_demands=%d", latency, len(doc_demand_ids))

        # IMPORTANT: wrapper. Your old score.py returned {"predictions": document}
        # Keep that to avoid breaking the app.
        return {"predictions": document}

    except Exception as e:
        # Donâ€™t crash container; return explicit error + log stacktrace.
        logger.exception("Unhandled error in run()")
        return {"error": "Internal server error", "detail": str(e)}


