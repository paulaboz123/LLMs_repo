import json
import os
import re
import logging
from typing import Any, Dict, List, Optional

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

CLIENT = None

AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_API_KEY = os.getenv("AZURE_OPENAI_API_KEY")
AZURE_OPENAI_API_VERSION = os.getenv("AZURE_OPENAI_API_VERSION", "2024-02-15-preview")

# IMPORTANT: your env name
AZURE_OPENAI_DEPLOYMENT = (
    os.getenv("AZURE_OPENAI_CHAT_DEPLOYMENT")
    or os.getenv("AZURE_OPENAI_DEPLOYMENT")
)

DEMANDS_CONTEXT = ""
MIN_DEMAND_PROB = float(os.getenv("MIN_DEMAND_PROB", "0.30"))
MAX_RETURN_IDS = int(os.getenv("MAX_RETURN_IDS", "50"))

_JSON_OBJ_RE = re.compile(r"\{.*\}", re.DOTALL)


def _safe_response(ids: Optional[List[str]] = None) -> Dict[str, Any]:
    # This is the known-good contract:
    return {"predictions": {"documentDemandPredictions": ids or []}}


def _coerce_request(raw_data: Any) -> Dict[str, Any]:
    try:
        if raw_data is None:
            return {}
        if isinstance(raw_data, (bytes, bytearray)):
            raw_data = raw_data.decode("utf-8", errors="ignore")
        if isinstance(raw_data, str):
            raw_data = raw_data.strip()
            if not raw_data:
                return {}
            return json.loads(raw_data)
        if isinstance(raw_data, dict):
            return raw_data
        return json.loads(str(raw_data))
    except Exception:
        return {}


def _safe_json_extract(text: str) -> Dict[str, Any]:
    text = (text or "").strip()
    if not text:
        return {}
    if text.startswith("```"):
        text = text.strip("`").strip()
        parts = text.splitlines()
        if parts and re.match(r"^[a-zA-Z]+$", parts[0].strip()):
            text = "\n".join(parts[1:]).strip()
    try:
        return json.loads(text)
    except Exception:
        m = _JSON_OBJ_RE.search(text)
        if not m:
            return {}
        try:
            return json.loads(m.group(0))
        except Exception:
            return {}


def _here() -> str:
    return os.path.dirname(os.path.abspath(__file__))


def _try_load_demands_xlsx() -> str:
    """
    Optional. If it fails, we still run and return empty predictions.
    XLSX columns (case-insensitive): demand_id/id, demand, description
    """
    try:
        path = os.getenv("DEMANDS_PATH", "").strip()
        if path:
            if not os.path.isabs(path):
                path = os.path.join(_here(), path)
        else:
            path = os.path.join(_here(), "demands.xlsx")

        if not os.path.exists(path):
            logger.warning("demands.xlsx not found at %s (continuing without demands context).", path)
            return ""

        from openpyxl import load_workbook  # type: ignore
        wb = load_workbook(path, read_only=True, data_only=True)
        ws = wb.active

        rows = list(ws.iter_rows(values_only=True))
        if len(rows) < 2:
            logger.warning("demands.xlsx has no data rows (continuing without demands context).")
            return ""

        headers = [str(h).strip().lower() for h in rows[0]]

        def idx(*names):
            for n in names:
                if n in headers:
                    return headers.index(n)
            return None

        i_id = idx("demand_id", "id")
        i_name = idx("demand")
        i_desc = idx("description")
        if i_id is None or i_name is None or i_desc is None:
            logger.warning("demands.xlsx missing required columns. headers=%s", headers)
            return ""

        lines = []
        for r in rows[1:]:
            did = str((r[i_id] if i_id < len(r) else "") or "").strip()
            name = str((r[i_name] if i_name < len(r) else "") or "").strip()
            desc = str((r[i_desc] if i_desc < len(r) else "") or "").strip()
            if not did:
                continue
            if len(desc) > 450:
                desc = desc[:450] + "â€¦"
            lines.append(f"- id: {did}\n  name: {name}\n  description: {desc}")

        ctx = "\n".join(lines)
        logger.info("Loaded demands context count=%d from %s", len(lines), path)
        return ctx

    except Exception as e:
        logger.warning("Failed to load demands.xlsx: %s (continuing without demands context).", str(e))
        return ""


def _init_openai_client():
    try:
        from openai import AzureOpenAI  # type: ignore
        if not AZURE_OPENAI_ENDPOINT or not AZURE_OPENAI_API_KEY or not AZURE_OPENAI_DEPLOYMENT:
            logger.warning("Azure OpenAI env missing (endpoint/key/deployment).")
            return None
        return AzureOpenAI(
            azure_endpoint=AZURE_OPENAI_ENDPOINT,
            api_key=AZURE_OPENAI_API_KEY,
            api_version=AZURE_OPENAI_API_VERSION,
        )
    except Exception as e:
        logger.warning("OpenAI client init failed: %s", str(e))
        return None


def init():
    """
    Must not crash the container.
    """
    global CLIENT, DEMANDS_CONTEXT
    CLIENT = _init_openai_client()
    DEMANDS_CONTEXT = _try_load_demands_xlsx()
    logger.info("init complete. client=%s deployment=%s", "ok" if CLIENT else "none", AZURE_OPENAI_DEPLOYMENT)


def _classify_text_to_ids(text: str, num_preds: int) -> List[str]:
    """
    Minimal, safe classification. Never raises.
    Returns demandIds list (strings).
    """
    if CLIENT is None or not AZURE_OPENAI_DEPLOYMENT:
        return []

    # If demands aren't loaded, don't hallucinate ids
    if not DEMANDS_CONTEXT.strip():
        return []

    sys_msg = "Return ONLY valid JSON. Never invent IDs."
    user_msg = f"""
Use ONLY demand IDs from the list below. If nothing fits, return empty demandIds.

Demands:
{DEMANDS_CONTEXT}

Text:
{text}

Return JSON ONLY:
{{
  "demandIds": [{{"id":"<one_of_the_listed_ids>","probability":0.85}}]
}}
""".strip()

    try:
        resp = CLIENT.chat.completions.create(
            model=AZURE_OPENAI_DEPLOYMENT,
            messages=[
                {"role": "system", "content": sys_msg},
                {"role": "user", "content": user_msg},
            ],
            temperature=0.0,
            max_tokens=500,
        )
        obj = _safe_json_extract(resp.choices[0].message.content or "")
        demand_ids = obj.get("demandIds") or []
        out: List[str] = []
        if isinstance(demand_ids, list):
            for d in demand_ids:
                if not isinstance(d, dict):
                    continue
                did = str(d.get("id") or "").strip()
                if not did:
                    continue
                try:
                    p = float(d.get("probability") or 0.0)
                except Exception:
                    p = 0.0
                if p >= MIN_DEMAND_PROB:
                    out.append(did)

        # cap
        out = out[: max(1, min(int(num_preds or 3), 10))]
        return out
    except Exception:
        return []


def run(raw_data):
    """
    Must NEVER throw.
    Must return the known-good minimal contract.
    """
    try:
        req = _coerce_request(raw_data)
        if not isinstance(req, dict):
            return _safe_response([])

        document = req.get("document")
        num_preds = int(req.get("num_preds", 3))

        # document may arrive as string
        if isinstance(document, str):
            try:
                document = json.loads(document)
            except Exception:
                document = None

        if not isinstance(document, dict):
            return _safe_response([])

        # Extract chunks if present; if not, still safe
        cd = document.get("contentDomain") or {}
        by_id = cd.get("byId") or {}
        if not isinstance(by_id, dict) or not by_id:
            return _safe_response([])

        seen = set()
        global_ids: List[str] = []

        # Keep it light and safe: pick ids across chunks
        for _, content in by_id.items():
            if not isinstance(content, dict):
                continue
            text = str(content.get("text") or "").strip()
            if len(text) < 10:
                continue
            ids = _classify_text_to_ids(text, num_preds)
            for did in ids:
                if did not in seen:
                    seen.add(did)
                    global_ids.append(did)
                if len(global_ids) >= MAX_RETURN_IDS:
                    break
            if len(global_ids) >= MAX_RETURN_IDS:
                break

        return _safe_response(global_ids)

    except Exception:
        return _safe_response([])
