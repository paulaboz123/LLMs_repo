import json
import os
import time
import logging
import re
from typing import Any, Dict, List, Tuple, Optional

import pandas as pd

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Globals
CLIENT = None
DEMANDS: List[Dict[str, str]] = []
DEMANDS_CONTEXT: str = ""

# Tunables (start permissive to actually highlight)
RELEVANCE_THRESHOLD = float(os.getenv("RELEVANCE_THRESHOLD", "0.45"))
MAX_DEMANDS_PER_CHUNK = int(os.getenv("MAX_DEMANDS_PER_CHUNK", "3"))

# Azure OpenAI config
AOAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AOAI_KEY = os.getenv("AZURE_OPENAI_API_KEY")
AOAI_API_VERSION = os.getenv("AZURE_OPENAI_API_VERSION", "2024-02-15-preview")
# IMPORTANT: your env name
AOAI_DEPLOYMENT = (
    os.getenv("AZURE_OPENAI_CHAT_DEPLOYMENT")
    or os.getenv("AZURE_OPENAI_DEPLOYMENT")
)

def _here() -> str:
    return os.path.dirname(os.path.abspath(__file__))

def _safe_json_extract(text: str) -> Dict[str, Any]:
    """Extract first JSON object from model output."""
    text = (text or "").strip()
    if not text:
        return {}
    # strip fenced blocks
    if text.startswith("```"):
        text = text.strip("`").strip()
        parts = text.splitlines()
        if parts and re.match(r"^[a-zA-Z]+$", parts[0].strip()):
            text = "\n".join(parts[1:]).strip()
    try:
        return json.loads(text)
    except Exception:
        m = re.search(r"\{.*\}", text, re.DOTALL)
        if not m:
            return {}
        try:
            return json.loads(m.group(0))
        except Exception:
            return {}

def _load_demands_xlsx() -> List[Dict[str, str]]:
    """
    Only XLSX. Expected in same folder as score.py (demands.xlsx) or set DEMANDS_PATH.
    Columns:
      - demand_id or id
      - demand
      - description   (your column name)
    """
    p = os.getenv("DEMANDS_PATH", "").strip()
    if p:
        if not os.path.isabs(p):
            p = os.path.join(_here(), p)
    else:
        p = os.path.join(_here(), "demands.xlsx")

    if not os.path.exists(p):
        raise FileNotFoundError(
            f"demands.xlsx not found at {p}. Put demands.xlsx next to score.py or set DEMANDS_PATH."
        )

    df = pd.read_excel(p)
    if df is None or df.empty:
        raise ValueError(f"demands.xlsx is empty: {p}")

    # normalize cols to lower
    df.columns = [str(c).strip().lower() for c in df.columns]

    id_col = "demand_id" if "demand_id" in df.columns else ("id" if "id" in df.columns else None)
    if not id_col:
        raise ValueError(f"demands.xlsx missing 'demand_id' or 'id'. Found: {list(df.columns)}")
    if "demand" not in df.columns:
        raise ValueError(f"demands.xlsx missing 'demand'. Found: {list(df.columns)}")
    # your column name:
    if "description" not in df.columns:
        raise ValueError(f"demands.xlsx missing 'description'. Found: {list(df.columns)}")

    out: List[Dict[str, str]] = []
    for _, r in df.fillna("").iterrows():
        did = str(r.get(id_col, "")).strip()
        name = str(r.get("demand", "")).strip()
        desc = str(r.get("description", "")).strip()
        if did:
            out.append({"id": did, "demand": name, "description": desc})

    if not out:
        raise ValueError("No valid rows in demands.xlsx after parsing.")
    logger.info("Loaded %d demands from %s", len(out), p)
    return out

def _build_demands_context(demands: List[Dict[str, str]]) -> str:
    # MUST include id explicitly, because model must output ids.
    lines = []
    for d in demands:
        desc = (d.get("description") or "").strip()
        if len(desc) > 450:
            desc = desc[:450] + "â€¦"
        lines.append(f"- id: {d['id']}\n  name: {d.get('demand','')}\n  description: {desc}")
    return "\n".join(lines)

def _init_openai_client():
    try:
        from openai import AzureOpenAI
    except Exception as e:
        raise RuntimeError("Missing python package 'openai' (AzureOpenAI).") from e

    if not AOAI_ENDPOINT or not AOAI_KEY or not AOAI_DEPLOYMENT:
        raise RuntimeError(
            "Missing Azure OpenAI env vars. Required: AZURE_OPENAI_ENDPOINT, AZURE_OPENAI_API_KEY, "
            "AZURE_OPENAI_CHAT_DEPLOYMENT (or AZURE_OPENAI_DEPLOYMENT)."
        )

    return AzureOpenAI(
        azure_endpoint=AOAI_ENDPOINT,
        api_key=AOAI_KEY,
        api_version=AOAI_API_VERSION,
    )

def init():
    global CLIENT, DEMANDS, DEMANDS_CONTEXT
    logger.info("init(): starting")
    DEMANDS = _load_demands_xlsx()
    DEMANDS_CONTEXT = _build_demands_context(DEMANDS)
    CLIENT = _init_openai_client()
    logger.info("init(): done, deployment=%s threshold=%.2f", AOAI_DEPLOYMENT, RELEVANCE_THRESHOLD)

def _prompt(chunk_id: str, chunk_text: str, num_preds: int) -> Tuple[str, str]:
    system = (
        "You are a strict requirements classifier for bid documentation. "
        "Return ONLY valid JSON. Never invent demand IDs."
    )
    user = f"""
Task:
1) Decide if the chunk contains a concrete customer requirement/specification that should be highlighted.
2) If yes, select up to {min(num_preds, MAX_DEMANDS_PER_CHUNK)} matching demands.

Rules:
- Use ONLY demand IDs listed in Demands below.
- Match based on demand description (WHEN). Name is only a hint.
- If NOT a requirement: set relevantProbability < 0.30 and return empty demandIds.
- If it IS a requirement: set relevantProbability in [0,1] and return matching demandIds.

Demands:
{DEMANDS_CONTEXT}

Chunk:
chunkId: {chunk_id}
text: {chunk_text}

Return JSON ONLY:
{{
  "chunkId": "{chunk_id}",
  "relevantProbability": 0.0,
  "demandIds": [{{"id":"<one_of_the_listed_ids>","probability":0.85}}],
  "explanation": "brief"
}}
""".strip()
    return system, user

def _classify_chunk(chunk_id: str, chunk_text: str, num_preds: int) -> Tuple[float, List[Dict[str, float]], str]:
    assert CLIENT is not None

    sys_msg, user_msg = _prompt(chunk_id, chunk_text, num_preds)
    resp = CLIENT.chat.completions.create(
        model=AOAI_DEPLOYMENT,
        messages=[
            {"role": "system", "content": sys_msg},
            {"role": "user", "content": user_msg},
        ],
        temperature=0.0,
        max_tokens=800,
    )
    content = (resp.choices[0].message.content or "").strip()
    obj = _safe_json_extract(content)

    rel = float(obj.get("relevantProbability") or 0.0)
    explanation = str(obj.get("explanation") or "")

    demand_ids = obj.get("demandIds") or []
    preds: List[Dict[str, float]] = []
    if isinstance(demand_ids, list):
        for d in demand_ids:
            if not isinstance(d, dict):
                continue
            did = str(d.get("id") or "").strip()
            if not did:
                continue
            try:
                p = float(d.get("probability") or 0.0)
            except Exception:
                p = 0.0
            if p >= 0.30:
                preds.append({"id": did, "probability": p})

    preds.sort(key=lambda x: x["probability"], reverse=True)
    preds = preds[: min(num_preds, MAX_DEMANDS_PER_CHUNK)]

    # If model says not relevant, force empty
    if rel < 0.30:
        preds = []

    return rel, preds, explanation

def _iter_chunks(document: Dict[str, Any]) -> List[Tuple[str, Dict[str, Any]]]:
    cd = document.get("contentDomain") or {}
    by_id = cd.get("byId") or {}
    if not isinstance(by_id, dict):
        return []
    return [(str(k), v) for (k, v) in by_id.items() if isinstance(v, dict)]

def inference(document: Dict[str, Any], num_preds: int) -> Dict[str, Any]:
    """
    Updates document in-place (contract-preserving):
    - per chunk: relevantProba, cdTransformerPredictions, cdLogregPredictions
    - documentDemandPredictions: LIST[str] (JSON array)
    """
    start = time.time()
    global_ids = set()

    for chunk_id, content in _iter_chunks(document):
        text = str(content.get("text") or "").strip()

        # Always ensure keys exist (UI stability)
        content["relevantProba"] = 0.0
        content["cdTransformerPredictions"] = []
        content["cdLogregPredictions"] = []

        if len(text) < 10:
            continue

        try:
            rel, preds, expl = _classify_chunk(chunk_id, text, num_preds)
        except Exception as e:
            logger.exception("Chunk %s classify failed: %s", chunk_id, str(e))
            continue

        content["relevantProba"] = float(rel)
        content["llmExplanation"] = expl  # debug, should not break app

        if rel >= RELEVANCE_THRESHOLD and preds:
            chunk_preds = [{"label": p["id"], "proba": float(p["probability"])} for p in preds]
            content["cdTransformerPredictions"] = chunk_preds
            content["cdLogregPredictions"] = chunk_preds  # keep legacy field for UI
            for p in preds:
                global_ids.add(p["id"])
        else:
            # keep empty predictions
            content["cdTransformerPredictions"] = []
            content["cdLogregPredictions"] = []

    # CRITICAL: must be JSON array (Python list), NOT a string.
    document["documentDemandPredictions"] = sorted(list(global_ids))

    logger.info("inference: chunks=%d global_ids=%d time=%.2fs",
                len(_iter_chunks(document)), len(document["documentDemandPredictions"]), time.time() - start)
    return document

def run(raw_data):
    """
    Entry point.
    Preserve the working contract:
      return {"predictions": <document>}
    Never return stringified arrays for documentDemandPredictions.
    """
    # Fail-safe: never crash app due to shape
    safe_doc = {"documentDemandPredictions": []}
    safe_resp = {"predictions": safe_doc}

    try:
        if raw_data is None:
            return safe_resp

        if isinstance(raw_data, (bytes, bytearray)):
            raw_data = raw_data.decode("utf-8", errors="ignore")

        req = json.loads(raw_data) if isinstance(raw_data, str) else raw_data
        if not isinstance(req, dict):
            return safe_resp

        if "document" not in req or "num_preds" not in req:
            return safe_resp

        document = req["document"]
        num_preds = int(req.get("num_preds", 3))

        if isinstance(document, str):
            document = json.loads(document)

        if not isinstance(document, dict):
            return safe_resp

        out_doc = inference(document, num_preds)
        return {"predictions": out_doc}

    except Exception as e:
        logger.error("run(): error %s", str(e), exc_info=True)
        return safe_resp
