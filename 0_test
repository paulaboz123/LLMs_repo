import os
import json
import time
import logging
from typing import Any, Dict, List, Optional

import pandas as pd
from openai import AzureOpenAI

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Azure OpenAI client
_client: Optional[AzureOpenAI] = None
_deployment: Optional[str] = None

# Demands (loaded from local file next to score.py)
_demands: List[Dict[str, str]] = []  # {"id":..., "name":..., "description":...}


# ----------------------------
# Utilities (hardening)
# ----------------------------
def _this_dir() -> str:
    return os.path.dirname(os.path.abspath(__file__))


def _ensure_list_of_strings(x: Any) -> List[str]:
    """
    CRITICAL: application expects JSON array of strings.
    If x is list of dicts -> extract "id".
    If x is a single string -> wrap into [string].
    Otherwise -> [].
    """
    if x is None:
        return []
    if isinstance(x, str):
        s = x.strip()
        return [s] if s else []
    if isinstance(x, list):
        out: List[str] = []
        for item in x:
            if isinstance(item, str):
                s = item.strip()
                if s:
                    out.append(s)
            elif isinstance(item, dict):
                # if someone mistakenly returns [{"id": "...", "probability": ...}]
                s = str(item.get("id", "")).strip()
                if s:
                    out.append(s)
        return out
    # sets, tuples, etc.
    try:
        return [str(v).strip() for v in list(x) if str(v).strip()]
    except Exception:
        return []


def _safe_json_loads(s: str) -> Optional[Any]:
    try:
        return json.loads(s)
    except Exception:
        return None


def _find_demands_file() -> str:
    base = _this_dir()
    # Demands obok score.py (jak u Ciebie)
    for name in ["demands.xlsx", "demands.csv", "demands.json"]:
        p = os.path.join(base, name)
        if os.path.isfile(p):
            return p
    raise FileNotFoundError("Missing demands file next to score.py (demands.xlsx/csv/json).")


def _load_demands() -> List[Dict[str, str]]:
    """
    Your Excel: demand_id, demand, demand_description
    We use demand_description for context, but output always uses demand_id.
    """
    path = _find_demands_file()
    logger.info(f"Loading demands from: {path}")

    if path.endswith(".xlsx"):
        df = pd.read_excel(path)
    elif path.endswith(".csv"):
        df = pd.read_csv(path)
    elif path.endswith(".json"):
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
        if isinstance(data, dict) and "demands" in data:
            data = data["demands"]
        out = []
        for d in data if isinstance(data, list) else []:
            if not isinstance(d, dict):
                continue
            did = str(d.get("demand_id") or d.get("id") or "").strip()
            name = str(d.get("demand") or d.get("name") or "").strip()
            desc = str(d.get("demand_description") or d.get("description") or d.get("clarification") or "").strip()
            if did:
                out.append({"id": did, "name": name, "description": desc})
        return out
    else:
        raise ValueError("Unsupported demands file type.")

    # Normalize DF
    cols = {c.strip() for c in df.columns}
    req = {"demand_id", "demand", "demand_description"}
    missing = req - cols
    if missing:
        raise ValueError(f"Demands missing columns: {sorted(missing)}")

    out: List[Dict[str, str]] = []
    for _, row in df.iterrows():
        did = str(row["demand_id"]).strip()
        name = str(row["demand"]).strip()
        desc = str(row["demand_description"]).strip()
        if did:
            out.append({"id": did, "name": name, "description": desc})
    return out


def _demands_context(demands: List[Dict[str, str]]) -> str:
    # Keep compact; description is key for match
    return "\n".join(
        f"- ID: {d['id']}\n  Name: {d['name']}\n  Clarification: {d['description']}"
        for d in demands
    )


def _prompt(demands_ctx: str, chunk_id: str, c_

